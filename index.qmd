---
title: "Conceptualizing open health data platforms for low- and middle income countries"
format:
  elsevier-html:
    toc: true
    toc-depth: 2
    fig-cap-location: top
    code-fold: true
  elsevier-pdf:
    keep-tex: true
    journal:
      name: JIMR
      cite-style: authoryear
author:
  - name: Daniel Kapitan
    affiliations:
      - name: PharmAccess Foundation
        city: Amsterdam
        country: the Netherlands
      - name: Eindhoven University of Technology
        city: Eindhoven
        country: the Netherlands
    orcid: 0000-0001-8979-9194
    email: daniel@kapitan.net
  - name: Femke Heddema
    affiliations:
      - name: PharmAccess Foundation
        city: Amsterdam
        country: the Netherlands
  - name: Julie Fleischer
    affiliations:
      - name: PharmAccess Foundation
        city: Amsterdam
        country: the Netherlands
  - name: Chris Ihure
    affiliations:
      - name: PharmAccess Kenya
        city: Nairobi
        country: Kenya
  - name: Antragama Abbas
    affiliations:
      - name: Delft University of Technology
        city: Delft
        country: the Netherlands
  - name: Steven Wanyee
    affiliations:
      - name: IntelliSOFT
        city: Nairobi
        country: Kenya
  - name: Alessandro Pietrobon 
    affiliations:
      - name: ONA
        city: Nairobi
        country: Kenya
  - name: John Grimes
    affiliations:
      - name: Australian e-Health Research Centre
        city: Brisbane
        country: Australia
  - name: Mark van der Graaf
    affiliations:
      - name: PharmAccess Foundation
        city: Amsterdam
        country: the Netherlands
  - name: Mark de Reuver
    affiliations:
      - name: Delft University of Technology
        city: Delft
        country: the Netherlands

        
abstract: |
  TO DO: add abstract.
keywords: [Analytics-on-FHIR, SQL-on-FHIR, HIE, data platforms, LMICs, digital health]
reference-section-title: References
bibliography: pharmaccess.bib
---

## Introduction {#sec-intro}

### The paradox of open for digital vs. data platforms in healthcare

It is a widely held belief that digital technologies have an important role to play in strengthening health systems in low- and middle income countries (LMICs), as exemplified by the WHO global strategy on digital health [@who2021global]. The adoption rate of mobile phones in LMICs has been an important driver in implementing digital health solutions [@mccool2022mobile]. Yet, there are many shortcomings and challenges, including the current fragmentation of digital platforms and the lack of clear-cut pathways of scaling up digital health programmes, such that they can support sustainable and equitable change of national health systems in LMICs [@mccool2022mobile;@who2019recommendations;@neumark2021digital].

A commonly used perspective to scrutinize digital health is to consider it as a digital platform [@dereuver2018digital]. Digital platforms have disrupted many sectors but have just started to make inroads into highly regulated industries such as healthcare [@ozalp2022digital]. In this light, the challenges faced by LMICs in establishing national digital health platforms have a lot in common with those faced by high income countries. From a technological perspective, interoperability issues, weak integrations, siloed data repositories and overall lack of openness are often reported as key impediments [@malm-nicolais2023exploring;@mehl2023fullstac]. From a societal perspective, issues pertaining to the winner-takes-all nature of digital platforms are hotly debated as many jurisdictions make work to ensure these new digital health platforms indeed serve the common good of achieving universal health coverage [@sharon2018when].

Case studies on digital platforms in healthcare point to an emerging pattern where the focus shifts from the digital platform with its defining software and hardware components, to the data as the primary object of interest in and of itself [@ozalp2022digital;@alaimo2022organizations]. This observation ties into the proposed research agenda by de Reuver et al. to consider data platforms as a phenomenon distinct from digital platforms [@dereuver2022openness]. Generally, data platforms inherit the characteristics of digital platforms. For example, the economic perspective on digital platforms stresses their multi-sidedness with developers and consumers, while data platforms are used by data owners, data consumers and third party solution providers. At the same time, data platforms differ as their main offerings revolve around data. From a market perspective, data platforms have more moderate network effects and are more susceptible to fragmentation and heterogeneity.

Particularly relevant in the context of health data platforms (HDPs), is the conceptualization of openness. The shift in perspective from digital platforms to data platforms coincides with the paradox of open [@keller2021paradox]. Originally, openness of digital platforms focused on open source, open standards and copyrights, which by has been superseded by “... conflicts about privacy, economic value extraction, the emergence of artificial intelligence, and the destabilizing effects of dominant platforms on (democratic) societies. Instead of access to information, the control of personal data has emerged in the age of platforms as the critical contention.” [@keller2021paradox]. These conflicts are particularly salient in the healthcare domain, as is evidenced by the polemic surrounding data spaces [@otto2022designing] and data solidarity [@kickbusch2021lancet;@prainsack2022data;@prainsack2023beyond]. Openness is particularly relevant if we are to realize a solidarity-based approach to health data sharing that i) gives people a greater control over their data as active decision makers; ii) ensures that the value of data is harnessed for public good; and iii) moves society towards equity and justice by counteracting dynamics of data extraction [@prainsack2022data].  

### From health information exchanges to health data platforms

This paper is motivated by the conflation of a number of developments relevant to the design and implementation of open, solidarity-based HDPs in LMICs. First, the OpenHIE framework [@openhie] has been adopted by many sub-Saharan African countries [@mamuye2022health] as the architectural blueprint for implementing nation-wide health information exchanges (HIE), including Nigeria [@dalhatu2023paper], Kenya [@thaiya2021adoption] and Tanzania [@nsaghurwe2021one]. These countries have, as a matter of course, extended the framework to include “analytics services” as an additional domain. The rationale for this addition is to facilitate secondary reuse of health data for academic research, real-world evidence studies etc. which can be framed within the context of ongoing efforts towards Findable, Accessible, Interoperable and Reusable (FAIR) sharing of health data [@guillot2023fair]. In doing so, however, we have implicitly moved from conceptualizing digital health platforms (the original OpenHIE specification) to health data platforms. This is problematic because the notion of openness, which is assumed to be essential in establishing solidarity-based approaches to data sharing, is inherently different for a data platform compared to a digital platform.

Conceptually, the OpenHIE framework constitutes a framework for an open digital platform. Openness for digital platforms refers to i) the use of open boundary resources, that is, specifications for the various healthcare specific workflows and information standards such as FHIR; and ii) the use of open source components that are available as digital public goods [@digitalpublicgoods]. If we are to use the OpenHIE framework as an open data platform, we need to extend the standards, technologies and architecture to include functionality for data sharing and reuse. The lack of detailed specifications and consensus of this addition to OpenHIE currently stands in the way of development projects that aim to establish HDPs in LMICs.  The purpose of this paper, therefore, is to specificy how new standards and technologies can be integrated into the OpenHIE architecture such that an open HDP can be realized that supports the four types of data sharing as defined by de Reuver at al. (@tbl-types-data-sharing).

|   | __Type of data sharing__ | __Technology enablers to create openness of health data platforms__ |
|:-:|:-------|:-------------|
| __1__ | Data at the most granular (patient) level, which is persisted and used to provide a longitudinal record. | __Bulk FHIR API__: has by now been incorporated in all major FHIR implementations the FHIR standard can be readily used to support data sharing to patient-level data across a patient population [@mandl2020push;@jones2021landscape]. |
| __2__ | Aggregated data, for example statistics for policy evaluation and benchmarking |__SQL-on-FHIR specification__ [@sql-on-fhir]: provides a standardised approach to make FHIR work well with familiar and efficient SQL engines that are most commonly used in analytical workflows. Builds on FHIRPath [@hl72020fhirpath] expressions in a logical structure to specify things like column names and unnested items. Implementations of this approach are available or forthcoming, including open source implementations such as Pathling [@grimes2022pathling] and commercial offerings like Aidbox [@aidbox].|
| __3__ | Data analytics modules, that provide access to work and access the data. | __Federated learning (FL)__ [@rieke2020future] and __privacy- enhancing technologies (PETs)__ [@scheibner2021revolutionizing;@jordan2022selecting]: new paradigms that address the problem of data governance and privacy by training algorithms collaboratively without exchanging the data itself. Models can be trained on combined datasets and made available as open source artifacts for decision support. Data analysts can use FL and PETs to work with the data in a collaborative, decentralized fashion. |
| __4__ | Trained models that have been derived from the data and can be used stand-alone for decision support. | __ONNX__ [@onnx]: an open format built to represent machine learning models. |

: Types of data sharing and in relation to new standards and technology enablers to create openness. Taken from de Reuver et al. (2022). {#tbl-types-data-sharing}

## Methods

In this paper, we present a design that extends the OpenHIE specification to include the four types of data sharing mentioned above. Using the full-STAC approach [@mehl2023fullstac] we combine open standards, open technologies and open architectures into a coherent modular HDP platform that can be configured and reused across a variety of use-cases. We employ a formative, naturalistic evaluation to assess the technical risk and efficacy of the design [@venable2016feds]. Given that it is prohibitively expensive to evaluate the design a real-world setting, we aim to minimize technological risks and maximize the efficacy of the design by considering three examples of health data platforms in LMICs, namely:

 1. the OpenHIM platform ([https://jembi.gitbook.io/openhim-platform/](https://jembi.gitbook.io/openhim-platform/))
 2. the ONA Canopy platform [https://ona.io/home/services/canopy/](https://ona.io/home/services/canopy/)
 3. the work conducted at PharmAccess Foundation as part of the MomCare programme ([https://health-data-commons.pharmaccess.org](https://health-data-commons.pharmaccess.org)).

These three real-world implementations are evaluated along the following dimensions:

- What is the level of openness of the implementation, specifically in terms of the four types of data sharing and platform-to-platform opennenss?
- How are the core maintenance functions of the HDP implemented, where we particularly focus on functions related to metadata management, data lineage and access control mechanisms?
- Is the solution suitable for downward scalability, where we focus on the computer and storage requirements of the solution and assess the minimal requirements for on-site resources (computers, edge devices)

As part of our design research, we have taken a narrative approach in surveying existing scientific studies on health data platforms, focusing on the seminal reports and subsequently searching forward citations. In addition, we have searched the open source repositories (most notably GitHub) and the online communities (OpenHIE community, FHIR community) to search for relevant open standards, technologies and architectures. This paper should not be considered as a proper systematic review.

The main contributions of this paper are i) description of a framework for the components of the Data & Analysis Services that builds on current best practices from the data engineering community into the OpenHIE framework; ii) evaluation of different implementations and design options for type 1 and 2 data sharing within an extended OpenHIE architecture; and iii) provide open content for the MomCare implementation to facilitate adaptation and deployment. As such, it aims to inform future developments and implementation of open digital health platforms in LMICs.


## Design

### Open standards: using FHIR as the common data model

The recent convergence to FHIR as the de facto standard for information exchange has fuelled the development of OpenHIE. FHIR is currently used both for routine healthcare settings [@amar2024electronic;@ayaz2021fast] and clinical research settings [@duda2022hl7;@vorisek2022fast] and is increasingly being used in LMICs as well. The guidelines and standards of the African Union explicitly state FHIR is to be used as the messaging standard [@2023african]. The FHIR-native OpenSRP platform [@mehl2020open] has been deployed in 14 countries targeting various patient populations, amongst which a reference implementation of the WHO antenatal and neonatal care guidelines for midwives in Lombok, Indonesia [@summitinstitutefordevelopment2023bunda;@kurniawan2019midwife]. In India, FHIR is used as the underlying technology for the open Health Claims Exchange protocol specification, which has been adopted by the Indian government as the standard for e-claims handling [@hcx]. This range of utilizations showcase the standards’ widespread applicability. The proceedings of the OpenHIE conference 2023 attest to the fact that FHIR and open source technologies are embraced as critical enablers in implementing health information exchanges in LMICs [@ohie2023unconference].

Various studies have investigated the merits of FHIR and its performance vis-a-vis other healthcare standards. Comparisons between OpenEHR, ISO 13606, OMOP and FHIR have been made [@ayaz2023transforming;@mullie2023coda;@rinaldi2021openehr;@cremonesi2023need;@sinaci2023data;@tsafnat2024converge]. A study involving 10 experts comparing OpenEHR, ISO 13606 and FHIR concluded that i) these three standards are functionally and technically compatible, and therefore can be used side by side; and that ii) each of these standards have their strengths and limitations that correlate with their intended use as summarized in the @tbl-comparison.

![Comparison of OpenEHR, ISO 13606 and FHIR standards](images/comparison-ehr-standards.png){width=auto #tbl-comparison}

For an infectious diseases dataset with a limited scope, OpenEHR, OMOP and FHIR have been compared and found all to be equally suitable [@rinaldi2021openehr]. Comparing OMOP and FHIR, the latter has been found to support more granular mappings required for analytics and was therefore chosen as the standard for the CODA project [@mullie2023coda].

Although FHIR was originally designed only for exchange between systems, we propose to use it as the common data model for the design presented here for the following reasons:

- Industry adoption has significantly increased, as exemplified by FHIR-based offering by major cloud providers such as Google, Azure and AWS. Also, Africa CDC has explicitly chosen FHIR as the preferred standard;
- The widespread availibility of the Bulk FHIR API [@mandl2020push;@jones2021landscape] enables bulk, file-based batchwise processing for analytics using the lakehouse architecture as detailed in the next section;
- The concept of FHIR Profiles allow localisation to tailor the standard to a specific use case. A profile defines rules, extensions, and constraints for a resource. We posit that the possible penalty of this flexibility, namely having to manage different FHIR versions and/or profiles, is less of an issue in the context of LMICs where first priority is to exchange datasets such as the International Patient Summary (IPS) that are less complex compared to the requirements for high income countries;
- Being based on webstandards, the FHIR standard lends itself best for further separation of concerns as envisioned by the composable data stack. This is an important enabler for the downward scalability of the solution;
- With its inherent, graph-like nature, FHIR can be readily incorporated into the principles of FAIR data sharing, where FHIR-based data repositories can be integrated in an overarching netwerk of FAIR data stations [@sinaci2023data;@pedrera-jimenez2023can].

Possible risks pertaining to the use of FHIR as the common data model, most notably the possible incompatibilities and/or high costs of maintenance in supporting different versions, will be addressed in the Discussion.

### Open architecture: extending OpenHIE with a composable data stack

#### Evolving the data lakehouse to a composable data stack

Data management and analytics platforms have undergone significant changes since the first generation of data warehouses were introduced. Recent studies have shown that the current practice has converged towards the lakehouse as one of the most commonly used solution designs [@armbrust2021lakehouse;@hai2023data;@harby2022data]. Lakehouses typically have a zonal architecture that follow the Extract-Load-Transform pattern (ELT) where data is ingested from the source systems in bulk (E), delivered to storage with aligned schemas (L) and transformed into a format ready for analysis (T) [@hai2023data]. The discerning characteristic of the lakehouse architecture is its foundation on low-cost and directly-accessible storage that also provides traditional analytical DBMS management and performance features such as ACID transactions, data versioning, auditing, indexing, caching, and query optimization [@armbrust2021lakehouse]. Lakehouses thus combine the key benefits of data lakes and data warehouses: low-cost storage in an open format accessible by a variety of systems from the former, and powerful management and optimization features from the latter.

With respect to current implementations of lakehouse data platforms, we observe a proliferation of tools with as yet limited standards to improve technical interoperability. In the analysis of Pedreira et al. [@pedreira2023composable] the requirement for specialization in data management systems has evolved faster than our software development practices. This situation has created a siloed landscape composed of hundreds of products developed and maintained as monoliths, with limited reuse between systems. It has also affected the end users, who are often required to learn the idiosyncrasies of dozens of incompatible SQL and non-SQL API dialects, and settle for systems with incomplete functionality and inconsistent semantics. To remedy this, Pedreira et al. call to (re-)design and implement modern data platforms in terms of a 'composable data stack’ as a means to decrease development and maintenance cost and pick-up the speed of innovation.

While the lakehouse architecture separates the concerns of compute and storage, the composable data stack takes the separation of concerns is taken one step further. A composable data system (@fig-composable-data-stack), not only separates the storage (layer 3) and execution (layer 2), but also separates the user interface (layer 1) from the execution engine by introducing standards including Substrait for Intermediate Representation (standard A, IR) and Apache Arrow for data connectivity and data memory layout (standards B and C, respectively). The composable data stack can be implemented with current open source technologies (@fig-cds-examples). As an example, the Ibis user interface is currently sufficiently mature to offer a standardized dataframe interface to 19 different execution engines.

![The composable data stack. Image source: [https://voltrondata.com/codex](https://voltrondata.com/codex).](images/composable-data-stack.png){#fig-composable-data-stack}

![Examples of implementations of the composable data stack. Image source: [https://voltrondata.com/codex](https://voltrondata.com/codex).](images/composable-data-stack-implementation-2.png){#fig-cds-examples}

#### SQL-on-FHIR v2 as an intermediate representation for FHIR data in tabular format

The premise of separating the user interface from the execution engine is directly related to the key objective of the SQL-on-FHIR project ([https://build.fhir.org/ig/FHIR/sql-on-fhir-v2/](https://build.fhir.org/ig/FHIR/sql-on-fhir-v2/)), namely to make large-scale analysis of FHIR data accessible to a larger audience, portable between systems and to make FHIR data work well with the best available analytic tools, regardless of the technology stack. However, to use FHIR effectively analysts require a thorough understanding of the specification as FHIR is represented as a graph of resources, with detailed semantics defined for references between resources, data types, terminology, extensions, and many other aspects of the specification.  Most analytic and machine learning use cases require the preparation of FHIR data using transformations and tabular projections from its original form. The task of authoring these transformations and projections is not trivial and there is currently no standard mechanisms to support reuse.

The solution of the SQL-on-FHIR project is to provide a specification for defining tabular, use case-specific views of FHIR data. The view definition and the execution of the view are separated, in such a way that the definition is portable across systems while the execution engine (called runners) are system-specific tools or libraries that apply view definitions to the underlying data layer, optionally making use of annotations to optimize performance.

#### Extending OpenHIE with a FHIR-based composable data stack

We propose to extend the OpenHIE architecture with a "Data and Analytics Services" domain with different service layers by synthesizing the current best practices of the a lakehouse architecture of [@hai2023data;@harby2022data;@harby2024data] and the composable data stack [@pedreira2023composable] (@fig-ohie, @tbl-data-and-analysis-services). These 5 services are considered the core of the FHIR data platform, and although in practice often a downstream dashboarding or visualization component is used, that component is not the main focus of our analysis. Rather, we aim to elucidate and conceptualize the core "FHIR Data Lakehouse".

![Proposed extension of the OpenHIE architecture that includes "Data and Analytics Services" as an additional service domain.](./images/openhie-extended-architecture.png){#fig-ohie}

+-------------------+---------------------------------------------------------------------------------------+
| Service           | Functional requirements                                                               |
+===================+=======================================================================================+
| Ingestion         | - Bulk                                                                                |
|                   | - Streaming                                                                           |
+-------------------+---------------------------------------------------------------------------------------+
| Storage           | - File-based blob storage                                                             |
|                   | - Database optimized for online analytical processing (OLAP)
+-------------------+---------------------------------------------------------------------------------------+
| Maintenance       | - SQL-on-FHIR View defintions                                                         |
|                   | - Catalog and other maintenance-related functions as defined by Hai et al.            |
+-------------------+---------------------------------------------------------------------------------------+
| Processing        | - SQL-on-FHIR Runner                                                                  |
| & API             | - Execution engine on tabular data as defined in composable data stack                |
|                   | - Capability to participate as a node in federated learning / MPC network             |
|                   | - Read-only access to storage                                                         |  
+-------------------+---------------------------------------------------------------------------------------+
| Data              | - SQL interactive development environment (IDE)                                       |
| Consumer          | - Interactive notebook computing environment [@granger2021jupyter]                    |
|                   | - BI reporting, dashboarding and data visualization                                   |  
+-------------------+---------------------------------------------------------------------------------------+

: Definition of Data and Analysis Services {#tbl-data-and-analysis-services}

##### Ingestion

Default workflow is extraction of data from SHR using Bulk FHIR API. Data contains metadata (incl. FHIR versions) and fully qualified semantics, for example, coding systems. Despite this, metadata extraction and metadata modeling is still required to meet the FAIR requirements. Issues that need to be solved by these services:

- To prepare for future updates of FHIR versions
- Implement late-binding principle of having increasingly more specific FHIR profiles as bulk FHIR data propagates through lakehouse


##### Storage

- File-based:
  - from ndjson to parquet
  - possibly used delta lake for time versioning
  - separation of storage from compute not only for benefits of lower TCO, but also be ready for federated learning and MPC in future

- OLAP DBMS
  - Often columnar, like Clickhouse and BigQuery
  - 


##### Query & Processing

- fit in structure of OpenHIE specification
- check which workflows are related to analytics
- Hai calls this 'Maintenance'

##### Maintenance

- SQL-on-FHIR Views provide new standard to support mADX aggregate reporting !! We need to stress this, because this is an existing OpenHIE workflow
- Maintenance-related functions remain the same
- NB: orchestration falls under data provenance

##### Data consumers

- Many tools, often focus on creating information dashboards and visualizations
- Compatibility with processing & API: which query languages and interfaces are supported. Some dialect of SQL, some dialect of NoSQL, dataframe API, all of the above?


### Open technologies: deploying Instant OpenHIE with digital public goods

Today, many components of the OpenHIE specification are now available as a digital public goods, as listed in @tbl-digital-public-goods. To further ease the development, configuration and deployment of health information exchanges, the concept of 'Instant OpenHIE' has been championed to (i) allow implementers to engage with a preconfigured health information exchange solution and running tools (based on the architecture) and test their applicability and functionality with a real health context problem; and (ii) have a packaged reference version of the OpenHIE architecture that is comprised of a set of reference technologies and other appropriate tools that form the building blocks of the health information exchange that can be configured and extended to support particular use cases [@InstantOpenHIEv2]. Besides the core functional components of the OpenHIE architecture, the Instant OpenHIE toolkit allows packaging and integration of generic components such as Identity and Access Managment (IAM) and a reverse proxy gateway. In the following, we will evaluatie three of such configurations, with the aim to conceptualize and evaluate the proposed Data and Analytics Services domain of of the OpenHIE architecture.

| Category  | Component | Digital Public Good |
|:----------|:----------|:--------------------|
| **Interoperability layer (IOL)** | IOL | [OpenHIM](http://openhim.org) |
| **Registry Services** | Client Registry (CR) | [SanteMPI](https://help.santesuite.org/product-overview/santesuite-products/master-patient-index-santempi) |
| | | [JeMPI](https://jembi.gitbook.io/jempi/) |
| | | [OpenCR](https://www.openclientregistry.org/) |
| | Facility Registry (FR) | [Global Open Facility Registry (GOFR)](https://github.com/intrahealth/gofr) |
| | Health Worker Registry (HWR) | [iHRIS](https://www.ihris.org/ihris-50) |
| | Terminology Service (TS) | [OCL Terminology Service](https://openconceptlab.org/terminology-service/) |
| | Product Catalog (PC) | not available |
| **Business Domain Services** | Shared Health Record (SHR) | [HAPI FHIR](https://hapifhir.io/) |
| | | [Fhirbase](https://www.health-samurai.io/fhirbase) |
| | | [FHIR Server for Azure](https://github.com/microsoft/fhir-server) |
| | | [I-TECH-UW SHR](https://github.com/I-TECH-UW/shared-health-record) |
| | Health Management Information System (HMIS) | [DHIS2](http://dhis2.org/) |
| | Finance and Insurance Service (FIS) | [OpenIMIS](http://openimis.org/) |
| | Logistics Management Information System (LMIS) | [OpenLMIS](http://openlmis.org/) |
| **Generic** | Identity and Access Management (IAM) | [Keycloak](https://www.keycloak.org/) |
| | Gateway & proxy | [FHIR Information Gateway](https://github.com/google/fhir-gateway) |
| | Admin dashboard for SHR | [OpenSRP FHIR Web](https://github.com/onaio/fhir-web) |
| | Configuration and deployment | [Instant OpenHIE](https://jembi.gitbook.io/instant-v2/) |

: Overview of current open source implementations of components included in the OpenHIE specification that are FHIR-compatible. The category Analytics Services is not a part of the original OpenHIE and is discussed in the paper. Point-of-Service systems are excluded for brevity. A systematic review of such digital public goods is beyond the scope of this document. {#tbl-digital-public-goods .striped .hover .responsive}

## Evaluation

### OpenHIM platform

To evaluate the extended OpenHIE architecture described above, we first consider the OpenHIM Platform. The Open Health Information Mediator (OpenHIM, [http://openhim.org/](OpenHIMhttp://openhim.org/))) component is the reference implementation of the Interoperability Layer (IOL) as defined in the OpenHIE specification. The most current version (8.4.2 at the time of writing) provides all the core functions including central point of access for the services of the HIE; routing functions; central logging for auditing and debugging purposes; and orchestration/mediation mechanisms to co-ordinate requests. By extension, the OpenHIM Platform ([https://jembi.gitbook.io/openhim-platform](https://jembi.gitbook.io/openhim-platform)) is a reference implementation of a set of Instant OpenHIE configurations, refered to as 'recipes' in the documentation. In the following we will evaluate the recipe for "a central data repository with a data warehouse" that provides "A FHIR-based Shared Health record linked to a Master Patient Index (MPI) for linking and mathing patient demographics and a default reporting pipeline to transform and visualise FHIR data" ([https://jembi.gitbook.io/openhim-platform/recipes/central-data-repository-with-data-warehousing](https://jembi.gitbook.io/openhim-platform/recipes/central-data-repository-with-data-warehousing)).

![Overview of the default data stack of the OpenHIM Platform. The default stack (top, red) consists of Kafka, Clickhouse and Superset. An alternative solution based on the ELK stack is also supported (bottom, orange), consisting of Elasticsearch, Logstash and Kibana.](images/openhim-platform.png){#fig-openhim-platform}

@fig-openhim-platform shows a schematic overview of two data stacks that are supported in the OpenHIM platform. The Shared Health Record (SHR, implemented with HAPI FHIR server) and the Client Registry (CR, implemented with JeMPI server) are the sources that store clinical FHIR data and patient demographic data, respectively. The default data stack is based on streaming ingestion using Kafka into a Clickhouse database. As part of the ingestion, incoming FHIR bundles that contain multiple FHIR resources are unbundled in separate topics using a generic Kafka utility component. Subsequently, each FHIR resource topic is flatted with Kafka mappers that use FHIRPath. Superset is used as the tool for consuming the data to create dashboard visualizations.

The OpenHIM platform also support data and analytics based on the ELK stack, where data is ingested in bulk using Logstash, stored in Elasticsearch and made available for consumption in Kibana. Also here, the incoming FHIR bundles are unbundled in Logstash into separate FHIR resources. However, given that Elasticsearch is a document-based search engine, the FHIR resources are stored as-is with no flattening. Exploring and analysing the data requires writing queries in Elasticsearch Query Language (ES|QL), either through the query interface of Elasticsearch or using Kibana.

Evaluating these two data stacks, we see the following:

- Pattern of flattening FHIR resources with FHIRPath expressions is very close to the idea of SQL-on-FHIR. Although it doesn't adhere to this new standard in the strict sense, the philosophy of generating tabular views is the same
- When using the ELK stack, flattening is done at the end. Implementations of FHIRPath support Elasticsearch as an execution engine, also here 
- Main limitations: both Clickhouse en Elasticsearch don't follow decomposition of storage, compute and UI. Therefore, downward scaleability is limited.

#### Level of opennness

TO DO: evaluate openness of OpenHIM platform

#### Core maintenance functions

TO DO: evaluate maintenance functions

#### Downward scaleability

TO DO: evaluate downward scalability


### ONA Canopy

TO DO: add section describing ONA Canopy.

#### Level of opennness

TO DO: evaluate openness of OpenHIM platform

#### Core maintenance functions

TO DO: evaluate maintenance functions

#### Downward scaleability

TO DO: evaluate downward scalability

### Momcare programme

MomCare was launched in Kenya [@huisman2022digital;@sanctis2022maintaining] and Tanzania [@shija2021access;@mrema2021application] in 2017 and 2019 respectively, with the objective to improve health outcomes for maternal and antenatal care. MomCare distinguishes two user groups: mothers are supported during their pregnancy through reminders and surveys, using SMS as the digital mode of engagement. Health workers are equipped with an Android-based application, in which visits, care activities and clinical observations are recorded. Reimbursements of the maternal clinic are based on the data captured with SMS and the app, thereby creating a conditional payment scheme, where providers are partially reimbursed up-front for a fixed bundle of activities, supplemented by bonus payments based on a predefined set of care activities.

In its original form, the MomCare programme used closed digital platforms. In Kenya, M-TIBA is the primary digital platform, on top of which a relatively lightweight custom app has been built as the engagement layer for the health workers [@huisman2022digital]. M-TIBA provides data access through its data warehouse platform for the MomCare programme, however, this is not a standardized, general purpose API. In the case of Tanzania, a stand-alone custom app is used which does not provide an interface of any kind for interacting with the platform [@mrema2021application]. Given these constraints, the first iteration of the MomCare programme used a custom-built data warehouse environment as its main data platform, on which data extractions, transformations and analysis are performed to generate the operational reports. Feedback reports for the health workers, in the form of operational dashboards, are made accessible through the app. Similar reports are provided to the back-office for the periodic reimbursement to the clinics.

Clearly, a more open and scaleable platform was required if MomCare was to be implemented in more regions. This need led to a redesign of the underlying technical infrastructure of the MomCare project. The objectives of this work were in fact to demonstrate a solution design that could support the first three types of data sharing listed in @tbl-types-data-sharing. First, to investigate the viability of using FHIR for bulk data sharing, MomCare Tanzania was used a testbed to assess the complexity and effort required to implement the facade pattern to integrate the legacy system into the FHIR data standard. Using the longitudinal dataset from approximately 28 thousand patient records, FHIR transformations script were developed and deployed using the mediator function of the IOL. The data was transformed into 10 FHIR v4 resources and the conceptual data model of the existing MomCare app could readily be transformed into the FHIR standard using SQL and validated with a Python library [@islam2023fhir]. The largest challenge during the transformation process pertained to the absence of unique business identifiers for patients and healthcare organizations. For patients, either the mobile phone number or the healthcare insurance number was taken, depending on availability. A combination of name, address and latitude/longitude coordinates were used to uniquely identify organizations and locations, as Tanzania does not have a system in place for this purpose.

The second objective was to reproduce existing analytic reports, using the bulk FHIR data format as input. Here, the focus was to standardize the logic required for producing metrics and reports. The transformed and validated data is uploaded into the FHIR server on a daily basis using an automated cloud function. Analysis of bulk data was done by directly reading the standard newline delimited JSON into the Python pandas data analysis library. Cross checking the output with queries on the original data confirmed that the whole data pipeline produced consistent results. For example, the report of the antenatal coverage metric (number of pregnancies with four or more visits) could be reproduced per patient journey and aggregated (per year, per organization etc.) as required for the MomCare reports.

TO DO: explain logic of patient-timeline table. Write standard transformation to go from FHIR resources to this standard table. On top of that the actual metrics and reporting. Explain serverless: we wanted to get rid of resource-heavy data visualization tools. This led to the idea of serverless: using duckdb-wasm and pipelines of cloud functions.

The third objective was to run a technical feasibility test for federated analytics. Using the MPC platform of Roseman Labs, we managed to do aggregations in the blind ...
TO DO: explain that we managed to reproduce the reports we generated in the clear, but then in the blind. Note, however, that in the remainder we will focus on first two types of data sharing.

Based on these experiments, we arrived at the following design for the data & analytics services

- Use 'serverless' file-based storage: bulk copy of data as-is in parquet
  - Tension: how to manage change data capture
  - Tension: how to manage access rights
- Use SQL-on-FHIR-v2 to create tabular views.
  - Example: patient timeline
  - TO DO: rewrite patient timeline queries with SQL-on-FHIR-v2 and run it with Pathling
- Use semantic modeling layer to define metrics
  - There are many options: dbt, cube.dev
  - Fulfills same function as ADX/mADX IHE profile in OpenHIE specification
  - Tension: going from patient-timeline to reported metrics still isn't standardized. This is where Ibis/Substrait comes in. Substrait as IR for cross-language serialization for relational algebra. Can be executed on different backends. Write once, run on different engines. 
- Distribute and publish reports on resource-constrained devices 
  - duckdb
  - sveltekit

TO DO: Add diagram

#### Level of opennness

TO DO: evaluate openness of OpenHIM platform

#### Core maintenance functions

TO DO: evaluate maintenance functions

#### Downward scaleability

TO DO: evaluate downward scalability


## Discussion

### Openness of data platforms

We specifically address the notion of openness of HDPs in LMICs in terms of the design-related questions put forward by de Reuver at al.11:

- Object of openness: what data-related resources should data platforms make available when opening up (e.g. data, data products, datadriven insights, analytics modules)? Which user groups derive value from accessing data-related resources from data platforms (e.g. data providers, data users, intermediaries, developers)?
- Unit of analysis: what is platform-to-platform openness in the context of data platforms, given the expectation that different HDPs will emerge at various aggregation levels? How do we distinguish meta-platforms, forking, and platform interoperability?
- Risk of openness: What are the novel (negative) implications of opening up data platforms? How can reflexivity in design help providers to resolve the negative implications of openness?
- Answers/insights to above:
  - Openness of standardized view on FHIR data and cross-language serialization of relational algebra makes it possible to fully standardize the workflow from start to finish
  - Platform-to-platform: MPC
  - Risk of openness: difficult to answer ...


### Comparison with HMIS component

- Workflow requirements: Report aggregate data (link): receiver is HMIS, mADX
- Functional requirements: https://guides.ohie.org/arch-spec/openhie-component-specifications-1/openhie-health-management-information-system-hmis

Requirements are similar, but implementation differs: Datamodel is non-FHIR, focused on DataValue, which conceptually equates to FHIR Measure

### The need to a semantic layer?

- FHIR and FAIR
  - How does FHIR relate to approaches taken by the FAIR community, which tend to take more an approach of using knowledge graphs. For example, VODAN Africa [@gebreslassie2023fhir4fair;@purnamajati2022data].
  - FAIR principles vs FHIR graph: is FHIR a FAIR Data Object

- Since we use FHIR, we don't need a semantic layer because that is already provided
- We do need different semantic layer, namely with metrics. Explain different types of semantics.
  - The metrics layer same function as CQL. Discuss CQL vs generic metrics layer.

### Attribute-based access control

- TO DO: if you have generated flattened SQL tables, how are you going to manage security?
- Cerbos, attribute based on lineage or anonymized tables
- Catalogs solve this: Tabular.io, Google BigLake. What is open source option?

### Federated learning and multiparty computation

- data stations??!


## Abbreviations

|    |    |
|:---|:---|
| CLI | Command-line Interface |
| CR | Client Registry |
| ELK | Elasticsearch, Logstach and Kibana stack |
| ELT | Extract, Load and Transform |
| FAIR |Findable, Accessible, Interoperable and Reusable |
| FHIR |Fast Healthcare Interoperability Resources |
| FL | Federated learning |
| HDP	|	Health data platform, explicitly differentiated from health digital platform |
| HIE | Health Information Exchange |
| IR | Intermediate Representation |
| LMIC | Low- and middle income countries |
| MPC | Multiparty Computation |
| PET | Privacy-enhancing technologies |
| SHR | Shared Health Record |

